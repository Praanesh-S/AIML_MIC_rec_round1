{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praanesh-S/AIML_MIC_rec_round1/blob/main/IMDb_Analysis_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "VttoepXXNdx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_filename = 'IMDB Dataset.csv'\n",
        "df = pd.read_csv(dataset_filename)\n",
        "\n",
        "print(f\"Dataset '{dataset_filename}' loaded successfully.\")\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "R7XxsP2jN0b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "metadata": {
        "id": "P2q-OhliN9IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "print(\"Text preprocessing complete.\")\n",
        "print(\"Example of original vs. cleaned review:\")\n",
        "print(\"\\nOriginal:\\n\", df['review'][0])\n",
        "print(\"\\nCleaned:\\n\", df['cleaned_review'][0])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "mMoK4he-N_YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['cleaned_review']\n",
        "y = df['sentiment']\n",
        "\n",
        "# Convert sentiment labels ('positive'/'negative') to numerical format (1/0)\n",
        "# as machine learning models require numerical input.\n",
        "y = y.map({'positive': 1, 'negative': 0})"
      ],
      "metadata": {
        "id": "_oI9d5cSOHRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training (80%) and testing (20%) sets.\n",
        "# `random_state` ensures the split is reproducible.\n",
        "# `stratify` ensures the proportion of sentiments is the same in both sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Data preparation and splitting complete.\")\n",
        "print(f\"Training set size: {len(X_train)} samples\")\n",
        "print(f\"Test set size: {len(X_test)} samples\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "UM8sJYCnOJn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 4: Vectorize the Text Data (Bag-of-Words)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize CountVectorizer to convert text into a matrix of token counts.\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Learn the vocabulary from the training data and transform it.\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vocabulary.\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Text vectorization complete.\")\n",
        "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())} words\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "sHNIE7K3OKKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 5: Train the Logistic Regression Model\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize the Logistic Regression model.\n",
        "# `max_iter=1000` is used to ensure the optimization algorithm converges.\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the model using the vectorized training data.\n",
        "print(\"Training the Logistic Regression model...\")\n",
        "model.fit(X_train_vec, y_train)\n",
        "print(\"Model training complete.\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "6hkQCSlrOMwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 6: Evaluate the Model\n",
        "# -----------------------------------------------------------------------------\n",
        "# Make predictions on the unseen test data.\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Calculate the model's accuracy.\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate a detailed classification report.\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "\n",
        "# Print the final evaluation results.\n",
        "print(\"--- Model Evaluation Results ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "print(\"--------------------------------\")"
      ],
      "metadata": {
        "id": "OpfWs8VtOOvl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}